{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b969a2c2",
   "metadata": {},
   "source": [
    "# DriftLens + FireRisk + Vision Transformer (folder-structured)\n",
    "\n",
    "This notebook runs two DriftLens experiments on the FireRisk dataset:\n",
    "\n",
    "1. **New-class drift** – \"Water\" is unseen in training and appears later in the stream.  \n",
    "2. **Gaussian blur drift** – all classes are seen in training; drift is injected via Gaussian blur.\n",
    "\n",
    "Assumed dataset layout:\n",
    "\n",
    "```text\n",
    "DATA_ROOT/\n",
    "    train/\n",
    "        High/\n",
    "        Low/\n",
    "        Moderate/\n",
    "        Non-burnable/\n",
    "        Very_High/\n",
    "        Very_Low/\n",
    "        Water/\n",
    "    val/\n",
    "        High/\n",
    "        Low/\n",
    "        Moderate/\n",
    "        Non-burnable/\n",
    "        Very_High/\n",
    "        Very_Low/\n",
    "        Water/\n",
    "```\n",
    "\n",
    "You’ll need:\n",
    "\n",
    "```bash\n",
    "pip install driftlens timm torch torchvision matplotlib scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde66585",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q driftlens timm torch torchvision matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from driftlens.driftlens import DriftLens\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# CHANGE THIS to your FireRisk root path\n",
    "DATA_ROOT = \"/home/joyvan/datasets/FireRisk\"\n",
    "\n",
    "assert os.path.isdir(DATA_ROOT), f\"FireRisk root not found: {DATA_ROOT}\"\n",
    "assert os.path.isdir(os.path.join(DATA_ROOT, \"train\")), \"Expected 'train' subfolder\"\n",
    "assert os.path.isdir(os.path.join(DATA_ROOT, \"val\")), \"Expected 'val' subfolder\"\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "default_window_size = 1000  # DriftLens window size\n",
    "default_epochs = 10         # adjust down if you want faster runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireRiskDataset(Dataset):\n",
    "    \"\"\"Folder-based FireRisk dataset.\n",
    "\n",
    "    Expects:\n",
    "        root/\n",
    "          train/\n",
    "            High/\n",
    "            Low/\n",
    "            Moderate/\n",
    "            Non-burnable/\n",
    "            Very_High/\n",
    "            Very_Low/\n",
    "            Water/\n",
    "          val/\n",
    "            High/\n",
    "            ...\n",
    "    \"\"\"\n",
    "    def __init__(self, root, split=\"train\", transform=None, classes_subset=None):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        train_root = os.path.join(root, \"train\")\n",
    "        assert os.path.isdir(train_root), f\"Missing train folder: {train_root}\"\n",
    "        all_classes = sorted(\n",
    "            d for d in os.listdir(train_root)\n",
    "            if os.path.isdir(os.path.join(train_root, d))\n",
    "        )\n",
    "        self.all_classes = all_classes\n",
    "\n",
    "        if classes_subset is not None:\n",
    "            selected_classes = sorted(classes_subset)\n",
    "            for c in selected_classes:\n",
    "                assert c in all_classes, f\"Unknown class in classes_subset: {c}\"\n",
    "        else:\n",
    "            selected_classes = all_classes\n",
    "\n",
    "        self.selected_classes = selected_classes\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(selected_classes)}\n",
    "        self.idx_to_class = {i: c for c, i in self.class_to_idx.items()}\n",
    "\n",
    "        split_root = os.path.join(root, split)\n",
    "        assert os.path.isdir(split_root), f\"Missing split folder: {split_root}\"\n",
    "\n",
    "        paths, labels = [], []\n",
    "        exts = (\"*.png\", \"*.jpg\", \"*.jpeg\")\n",
    "        for cls_name in selected_classes:\n",
    "            cls_dir = os.path.join(split_root, cls_name)\n",
    "            if not os.path.isdir(cls_dir):\n",
    "                continue\n",
    "            for ext in exts:\n",
    "                for p in glob.glob(os.path.join(cls_dir, ext)):\n",
    "                    paths.append(p)\n",
    "                    labels.append(self.class_to_idx[cls_name])\n",
    "\n",
    "        assert paths, f\"No images found in {split_root} for classes {selected_classes}\"\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img_path = self.paths[i]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[i]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b200230",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_ds_full = FireRiskDataset(DATA_ROOT, split=\"train\",\n",
    "                                transform=img_transform, classes_subset=None)\n",
    "val_ds_full   = FireRiskDataset(DATA_ROOT, split=\"val\",\n",
    "                                transform=img_transform, classes_subset=None)\n",
    "# use val as \"test\"\n",
    "test_ds_full  = val_ds_full\n",
    "\n",
    "train_loader_full = DataLoader(train_ds_full, batch_size=batch_size,\n",
    "                               shuffle=True, num_workers=num_workers)\n",
    "val_loader_full   = DataLoader(val_ds_full, batch_size=batch_size,\n",
    "                               shuffle=False, num_workers=num_workers)\n",
    "test_loader_full  = DataLoader(test_ds_full, batch_size=batch_size,\n",
    "                               shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(\"Full-train size:\", len(train_ds_full),\n",
    "      \"val/test size:\", len(val_ds_full))\n",
    "print(\"Discovered classes:\", train_ds_full.selected_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit(num_classes: int) -> nn.Module:\n",
    "    model = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "    if hasattr(model, \"head\"):\n",
    "        in_features = model.head.in_features\n",
    "        model.head = nn.Linear(in_features, num_classes)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unexpected ViT model structure.\")\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_epoch(model, loader, optimizer=None, criterion=None):\n",
    "    train = optimizer is not None\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "            feats = model.forward_features(x)\n",
    "            logits = model.head(feats)\n",
    "            loss = criterion(logits, y) if criterion is not None else None\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if loss is not None:\n",
    "                total_loss += float(loss.item()) * x.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total if total > 0 else 0.0\n",
    "    acc = total_correct / total if total > 0 else 0.0\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader,\n",
    "                epochs=default_epochs, lr=3e-4, wd=0.05):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc = run_epoch(model, val_loader)\n",
    "        history.append((epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "        print(f\"Epoch {epoch:02d} | \"\n",
    "              f\"train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
    "              f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_embeddings_and_preds(model, loader):\n",
    "    model.eval()\n",
    "    all_E, all_Y_hat, all_Y_true = [], [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        feats = model.forward_features(x)\n",
    "        logits = model.head(feats)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_E.append(feats.cpu())\n",
    "        all_Y_hat.append(preds.cpu())\n",
    "        all_Y_true.append(y)\n",
    "    E = torch.cat(all_E, dim=0).numpy()\n",
    "    Y_hat = torch.cat(all_Y_hat, dim=0).numpy()\n",
    "    Y_true = torch.cat(all_Y_true, dim=0).numpy()\n",
    "    return E, Y_hat, Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc712805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_driftlens_baseline(E_train, Y_pred_train,\n",
    "                           E_thr, Y_pred_thr,\n",
    "                           batch_n_pc=150,\n",
    "                           per_label_n_pc=75,\n",
    "                           window_size=default_window_size,\n",
    "                           n_samples=10000):\n",
    "    label_list = sorted(np.unique(Y_pred_train))\n",
    "    dl = DriftLens()\n",
    "    baseline = dl.estimate_baseline(\n",
    "        E=E_train,\n",
    "        Y=Y_pred_train,\n",
    "        label_list=label_list,\n",
    "        batch_n_pc=batch_n_pc,\n",
    "        per_label_n_pc=per_label_n_pc,\n",
    "    )\n",
    "    per_batch_sorted, per_label_sorted = dl.random_sampling_threshold_estimation(\n",
    "        label_list=label_list,\n",
    "        E=E_thr,\n",
    "        Y=Y_pred_thr,\n",
    "        batch_n_pc=batch_n_pc,\n",
    "        per_label_n_pc=per_label_n_pc,\n",
    "        window_size=window_size,\n",
    "        n_samples=n_samples,\n",
    "        flag_shuffle=True,\n",
    "        flag_replacement=True,\n",
    "    )\n",
    "    return dl, baseline, per_batch_sorted, per_label_sorted\n",
    "\n",
    "\n",
    "def compute_window_distances(dl, E_stream, Yp_stream, window_size):\n",
    "    n = E_stream.shape[0]\n",
    "    n_windows = n // window_size\n",
    "    distances = []\n",
    "    for w in range(n_windows):\n",
    "        s = w * window_size\n",
    "        e = s + window_size\n",
    "        Ew = E_stream[s:e]\n",
    "        Ypw = Yp_stream[s:e]\n",
    "        dist = dl.compute_window_distribution_distances(Ew, Ypw)\n",
    "        distances.append(dist)\n",
    "    return np.array(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13fc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All classes:\", train_ds_full.selected_classes)\n",
    "\n",
    "# Treat Water as the unseen \"new\" class\n",
    "classes_train_nc = {c for c in train_ds_full.selected_classes if c != \"Water\"}\n",
    "classes_new_nc = {\"Water\"}\n",
    "\n",
    "print(\"Train classes (no new class):\", classes_train_nc)\n",
    "print(\"New-class only in drift   :\", classes_new_nc)\n",
    "\n",
    "train_ds_nc = FireRiskDataset(DATA_ROOT, split=\"train\",\n",
    "                              transform=img_transform,\n",
    "                              classes_subset=classes_train_nc)\n",
    "val_ds_nc   = FireRiskDataset(DATA_ROOT, split=\"val\",\n",
    "                              transform=img_transform,\n",
    "                              classes_subset=classes_train_nc)\n",
    "test_ds_nc  = val_ds_nc  # reuse val as test\n",
    "\n",
    "train_loader_nc = DataLoader(train_ds_nc, batch_size=batch_size,\n",
    "                             shuffle=True, num_workers=num_workers)\n",
    "val_loader_nc   = DataLoader(val_ds_nc, batch_size=batch_size,\n",
    "                             shuffle=False, num_workers=num_workers)\n",
    "test_loader_nc  = DataLoader(test_ds_nc, batch_size=batch_size,\n",
    "                             shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(\"New-class train size:\", len(train_ds_nc),\n",
    "      \"val/test size:\", len(val_ds_nc))\n",
    "print(\"Selected classes:\", train_ds_nc.selected_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_nc = len(train_ds_nc.selected_classes)\n",
    "model_nc = create_vit(num_classes=num_classes_nc)\n",
    "_ = train_model(model_nc, train_loader_nc, val_loader_nc,\n",
    "                epochs=default_epochs)\n",
    "\n",
    "E_train_nc, Yp_train_nc, _ = get_embeddings_and_preds(model_nc, train_loader_nc)\n",
    "E_thr_nc,   Yp_thr_nc,   _ = get_embeddings_and_preds(model_nc, test_loader_nc)\n",
    "\n",
    "dl_nc, baseline_nc, per_batch_sorted_nc, per_label_sorted_nc = fit_driftlens_baseline(\n",
    "    E_train_nc, Yp_train_nc, E_thr_nc, Yp_thr_nc,\n",
    "    batch_n_pc=150, per_label_n_pc=75,\n",
    "    window_size=default_window_size, n_samples=10000,\n",
    ")\n",
    "\n",
    "print(\"Baseline fitted. Labels:\", sorted(np.unique(Yp_train_nc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all classes (including Water) from val as the source stream\n",
    "test_ds_all = FireRiskDataset(DATA_ROOT, split=\"val\",\n",
    "                              transform=img_transform,\n",
    "                              classes_subset=None)\n",
    "labels_all = test_ds_all.labels\n",
    "classes_all = test_ds_all.selected_classes\n",
    "\n",
    "indices_by_class = {cls_name: [] for cls_name in classes_all}\n",
    "for idx, lab in enumerate(labels_all):\n",
    "    cls_name = classes_all[lab]\n",
    "    indices_by_class[cls_name].append(idx)\n",
    "\n",
    "for c in indices_by_class:\n",
    "    random.shuffle(indices_by_class[c])\n",
    "\n",
    "window_size_nc = default_window_size\n",
    "target_windows_pre = 10\n",
    "target_windows_post = 10\n",
    "target_pre_len = target_windows_pre * window_size_nc\n",
    "target_post_len = target_windows_post * window_size_nc\n",
    "\n",
    "pre_indices = []\n",
    "while len(pre_indices) < target_pre_len:\n",
    "    exhausted = True\n",
    "    for c in classes_train_nc:\n",
    "        if indices_by_class[c]:\n",
    "            pre_indices.append(indices_by_class[c].pop())\n",
    "            exhausted = False\n",
    "            if len(pre_indices) >= target_pre_len:\n",
    "                break\n",
    "    if exhausted:\n",
    "        break\n",
    "\n",
    "post_indices = []\n",
    "while len(post_indices) < target_post_len:\n",
    "    exhausted = True\n",
    "    for c in classes_train_nc | classes_new_nc:\n",
    "        if indices_by_class[c]:\n",
    "            post_indices.append(indices_by_class[c].pop())\n",
    "            exhausted = False\n",
    "            if len(post_indices) >= target_post_len:\n",
    "                break\n",
    "    if exhausted:\n",
    "        break\n",
    "\n",
    "stream_indices_nc = pre_indices + post_indices\n",
    "stream_ds_nc = Subset(test_ds_all, stream_indices_nc)\n",
    "stream_loader_nc = DataLoader(stream_ds_nc, batch_size=batch_size,\n",
    "                              shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(\"Stream size (samples):\", len(stream_ds_nc))\n",
    "\n",
    "E_stream_nc, Yp_stream_nc, Ytrue_stream_nc = get_embeddings_and_preds(\n",
    "    model_nc, stream_loader_nc\n",
    ")\n",
    "distances_nc = compute_window_distances(\n",
    "    dl_nc, E_stream_nc, Yp_stream_nc, window_size=window_size_nc\n",
    ")\n",
    "print(\"Number of windows:\", len(distances_nc))\n",
    "\n",
    "approx_drift_window = (len(stream_indices_nc) // 2) // window_size_nc\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(distances_nc, marker=\"o\")\n",
    "plt.axvline(x=approx_drift_window - 0.5, linestyle=\"--\", label=\"drift start (approx)\")\n",
    "plt.xlabel(\"Window index\")\n",
    "plt.ylabel(\"DriftLens distance\")\n",
    "plt.title(\"New-class drift (Water) – FireRisk + ViT\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ac46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_full = len(train_ds_full.selected_classes)\n",
    "model_full = create_vit(num_classes=num_classes_full)\n",
    "_ = train_model(model_full, train_loader_full, val_loader_full,\n",
    "                epochs=default_epochs)\n",
    "\n",
    "E_train_full, Yp_train_full, _ = get_embeddings_and_preds(model_full, train_loader_full)\n",
    "E_thr_full,   Yp_thr_full,   _ = get_embeddings_and_preds(model_full, test_loader_full)\n",
    "\n",
    "dl_full, baseline_full, per_batch_sorted_full, per_label_sorted_full = fit_driftlens_baseline(\n",
    "    E_train_full, Yp_train_full, E_thr_full, Yp_thr_full,\n",
    "    batch_n_pc=150, per_label_n_pc=75,\n",
    "    window_size=default_window_size, n_samples=10000,\n",
    ")\n",
    "\n",
    "print(\"Baseline fitted (blur experiment). Labels:\",\n",
    "      sorted(np.unique(Yp_train_full)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.GaussianBlur(kernel_size=11, sigma=3.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "base_ds_clean = FireRiskDataset(DATA_ROOT, split=\"val\",\n",
    "                                transform=img_transform,   classes_subset=None)\n",
    "base_ds_blur  = FireRiskDataset(DATA_ROOT, split=\"val\",\n",
    "                                transform=blur_transform, classes_subset=None)\n",
    "\n",
    "assert base_ds_clean.paths == base_ds_blur.paths\n",
    "assert base_ds_clean.labels == base_ds_blur.labels\n",
    "\n",
    "clean_loader = DataLoader(base_ds_clean, batch_size=batch_size,\n",
    "                          shuffle=False, num_workers=num_workers)\n",
    "blur_loader  = DataLoader(base_ds_blur, batch_size=batch_size,\n",
    "                          shuffle=False, num_workers=num_workers)\n",
    "\n",
    "E_clean, Yp_clean, _ = get_embeddings_and_preds(model_full, clean_loader)\n",
    "E_blur,  Yp_blur,  _ = get_embeddings_and_preds(model_full, blur_loader)\n",
    "\n",
    "window_size_blur = default_window_size\n",
    "n_clean = (len(E_clean) // window_size_blur) * window_size_blur\n",
    "n_blur  = (len(E_blur) // window_size_blur) * window_size_blur\n",
    "n_clean = min(n_clean, 20 * window_size_blur)  # cap to at most 20 windows\n",
    "n_blur  = min(n_blur, 20 * window_size_blur)\n",
    "\n",
    "E_stream_blur = np.concatenate([E_clean[:n_clean], E_blur[:n_blur]], axis=0)\n",
    "Yp_stream_blur = np.concatenate([Yp_clean[:n_clean], Yp_blur[:n_blur]], axis=0)\n",
    "\n",
    "print(\"Stream sizes (clean, blur):\", n_clean, n_blur)\n",
    "\n",
    "distances_blur = compute_window_distances(\n",
    "    dl_full, E_stream_blur, Yp_stream_blur, window_size=window_size_blur\n",
    ")\n",
    "print(\"Number of windows:\", len(distances_blur))\n",
    "\n",
    "clean_windows = n_clean // window_size_blur\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(distances_blur, marker=\"o\")\n",
    "plt.axvline(x=clean_windows - 0.5, linestyle=\"--\", label=\"blur start\")\n",
    "plt.xlabel(\"Window index\")\n",
    "plt.ylabel(\"DriftLens distance\")\n",
    "plt.title(\"Gaussian blur drift – FireRisk + ViT\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
