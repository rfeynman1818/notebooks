{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAR Data Analysis for Model Development\n",
    "\n",
    "## ðŸ“¡ Comprehensive Data Pipeline for Machine Learning Engineers\n",
    "\n",
    "This notebook provides an end-to-end analysis pipeline for SAR imagery, specifically designed to inform ML engineers developing (Real-Time Detection Transformer) models for object detection in SAR data.\n",
    "\n",
    "### Key Objectives:\n",
    "1. **Metadata Extraction & Analysis** - Understanding data characteristics\n",
    "2. **Image Quality Assessment** - Evaluating data suitability for detection tasks\n",
    "3. **Statistical Analysis** - Distribution insights for model training\n",
    "4. **Preprocessing Recommendations** - Optimal data preparation for\n",
    "5. **Data Augmentation Strategies** - Enhancing model robustness\n",
    "6. **Performance Metrics** - Establishing baselines and expectations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import warnings\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Scientific Computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, signal\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Image Processing\n",
    "from skimage import measure, exposure, filters, morphology\n",
    "from skimage.feature import peak_local_max, corner_harris\n",
    "import cv2\n",
    "\n",
    "# SAR Processing\n",
    "from sarpy.io.complex import open_complex\n",
    "from shapely.geometry import shape, Point, Polygon\n",
    "\n",
    "# Progress Bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Custom Modules\n",
    "from metadata_extractor import SARMetadataExtractor\n",
    "from metadata_analysis import SARMetadataAnalyzer\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Visualization Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"âœ… Environment setup complete!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Specific Configuration and Constants\n",
    "\n",
    "###  SAR Characteristics:\n",
    "- **Frequency**: X-band (9.65 GHz)\n",
    "- **Wavelength**: ~3.1 cm\n",
    "- **Polarization**: VV (typically)\n",
    "- **Resolution**: Up to 25 cm (Spotlight mode)\n",
    "- **Imaging Modes**: Stripmap, Spotlight, ScanSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -specific constants\n",
    "_CONFIG = {\n",
    "    'frequency_ghz': 9.65,\n",
    "    'wavelength_cm': 3.1,\n",
    "    'polarization': 'VV',\n",
    "    'modes': {\n",
    "        'SPOTLIGHT': {'resolution_m': 0.25, 'scene_size_km': 5},\n",
    "        'STRIPMAP': {'resolution_m': 3.0, 'scene_size_km': 30},\n",
    "        'SCAN': {'resolution_m': 15.0, 'scene_size_km': 100}\n",
    "    },\n",
    "    'bit_depth': 16,\n",
    "    'complex_data': True\n",
    "}\n",
    "\n",
    "# Model Requirements\n",
    "RTDETR_CONFIG = {\n",
    "    'input_sizes': [640, 800, 1024],  # Common input sizes\n",
    "    'backbone': 'ResNet50',  # or ResNet101\n",
    "    'min_object_size': 32,  # Minimum object size in pixels\n",
    "    'max_objects_per_image': 100,\n",
    "    'confidence_threshold': 0.5,\n",
    "    'nms_threshold': 0.45,\n",
    "    'anchor_sizes': [32, 64, 128, 256, 512]\n",
    "}\n",
    "\n",
    "# ML Pipeline Configuration\n",
    "ML_CONFIG = {\n",
    "    'train_val_test_split': [0.7, 0.2, 0.1],\n",
    "    'augmentation_factor': 3,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-4,\n",
    "    'epochs': 100,\n",
    "    'early_stopping_patience': 10\n",
    "}\n",
    "\n",
    "print(\"ðŸ“¡  and configurations loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data directory\n",
    "data_dir = Path(input(\"Enter path to  SICD/XML files directory: \").strip())\n",
    "label_dir = Path(input(\"Enter path to annotation files directory (optional, press Enter to skip): \").strip() or \".\")\n",
    "\n",
    "# Initialize metadata extractor\n",
    "extractor = SARMetadataExtractor(data_dir)\n",
    "\n",
    "# Parse metadata\n",
    "print(\"\\nðŸ”„ Parsing  metadata...\")\n",
    "metadata = extractor.parse_sicd_metadata()\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "df_metadata = pd.DataFrame.from_dict(metadata, orient='index')\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(metadata)}  images\")\n",
    "print(f\"Metadata columns: {df_metadata.columns.tolist()[:10]}...\")\n",
    "print(f\"\\nDataFrame shape: {df_metadata.shape}\")\n",
    "\n",
    "# Display sample\n",
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Data Quality Assessment\n",
    "\n",
    "### Critical metrics for performance:\n",
    "1. **Signal-to-Noise Ratio (SNR)**\n",
    "2. **Equivalent Number of Looks (ENL)**\n",
    "3. **Radiometric Resolution**\n",
    "4. **Spatial Resolution Consistency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityAnalyzer:\n",
    "    \"\"\"Analyze  SAR image quality metrics for ML applications\"\"\"\n",
    "    \n",
    "    def __init__(self, metadata_df: pd.DataFrame):\n",
    "        self.df = metadata_df\n",
    "        self.quality_metrics = {}\n",
    "    \n",
    "    def calculate_snr(self, image: np.ndarray) -> float:\n",
    "        \"\"\"Calculate Signal-to-Noise Ratio\"\"\"\n",
    "        signal = np.mean(np.abs(image))\n",
    "        noise = np.std(np.abs(image))\n",
    "        return 20 * np.log10(signal / (noise + 1e-10))\n",
    "    \n",
    "    def calculate_enl(self, image: np.ndarray, window_size: int = 7) -> float:\n",
    "        \"\"\"Calculate Equivalent Number of Looks\"\"\"\n",
    "        # Use homogeneous regions for ENL calculation\n",
    "        h, w = image.shape\n",
    "        center = image[h//2-window_size:h//2+window_size, \n",
    "                      w//2-window_size:w//2+window_size]\n",
    "        mean_val = np.mean(center)\n",
    "        std_val = np.std(center)\n",
    "        return (mean_val / (std_val + 1e-10)) ** 2\n",
    "    \n",
    "    def calculate_edge_density(self, image: np.ndarray) -> float:\n",
    "        \"\"\"Calculate edge density (important for object detection)\"\"\"\n",
    "        edges = cv2.Canny((image * 255).astype(np.uint8), 50, 150)\n",
    "        return np.sum(edges > 0) / edges.size\n",
    "    \n",
    "    def calculate_contrast(self, image: np.ndarray) -> float:\n",
    "        \"\"\"Calculate image contrast using RMS method\"\"\"\n",
    "        return np.sqrt(np.mean((image - np.mean(image))**2))\n",
    "    \n",
    "    def analyze_resolution_consistency(self) -> Dict:\n",
    "        \"\"\"Analyze resolution consistency across dataset\"\"\"\n",
    "        resolutions = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            if 'NumRows' in row and 'NumCols' in row:\n",
    "                resolutions.append((row['NumRows'], row['NumCols']))\n",
    "        \n",
    "        resolution_counts = Counter(resolutions)\n",
    "        return {\n",
    "            'unique_resolutions': len(resolution_counts),\n",
    "            'most_common': resolution_counts.most_common(3),\n",
    "            'consistency_score': 1.0 / len(resolution_counts)  # Higher is better\n",
    "        }\n",
    "    \n",
    "    def generate_quality_report(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate comprehensive quality report\"\"\"\n",
    "        report = {\n",
    "            'metric': [],\n",
    "            'value': [],\n",
    "            'ml_impact': [],\n",
    "            'recommendation': []\n",
    "        }\n",
    "        \n",
    "        # Resolution analysis\n",
    "        res_analysis = self.analyze_resolution_consistency()\n",
    "        report['metric'].append('Resolution Consistency')\n",
    "        report['value'].append(f\"{res_analysis['consistency_score']:.2f}\")\n",
    "        report['ml_impact'].append('High' if res_analysis['consistency_score'] < 0.5 else 'Low')\n",
    "        report['recommendation'].append(\n",
    "            'Standardize input sizes' if res_analysis['consistency_score'] < 0.5 \n",
    "            else 'Resolution is consistent'\n",
    "        )\n",
    "        \n",
    "        return pd.DataFrame(report)\n",
    "\n",
    "# Initialize analyzer\n",
    "quality_analyzer = QualityAnalyzer(df_metadata)\n",
    "quality_report = quality_analyzer.generate_quality_report()\n",
    "\n",
    "print(\"ðŸ“Š Quality Assessment Report:\")\n",
    "display(quality_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Distribution Analysis for ML\n",
    "\n",
    "Understanding data distributions is crucial for:\n",
    "- **Normalization strategies**\n",
    "- **Outlier detection**\n",
    "- **Class imbalance assessment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive statistical analysis\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=(\n",
    "        'Incidence Angle Distribution',\n",
    "        'Image Size Distribution',\n",
    "        'Aspect Ratio Distribution',\n",
    "        'Temporal Distribution',\n",
    "        'Geospatial Coverage',\n",
    "        'Mode Distribution'\n",
    "    ),\n",
    "    specs=[\n",
    "        [{'type': 'histogram'}, {'type': 'box'}, {'type': 'histogram'}],\n",
    "        [{'type': 'scatter'}, {'type': 'scatter'}, {'type': 'bar'}]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 1. Incidence Angle Distribution\n",
    "if 'IncidenceAng' in df_metadata.columns:\n",
    "    angles = df_metadata['IncidenceAng'].dropna()\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=angles, name='Incidence Angle', nbinsx=30),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# 2. Image Size Distribution\n",
    "if 'NumRows' in df_metadata.columns and 'NumCols' in df_metadata.columns:\n",
    "    df_metadata['TotalPixels'] = df_metadata['NumRows'] * df_metadata['NumCols']\n",
    "    fig.add_trace(\n",
    "        go.Box(y=df_metadata['TotalPixels'].dropna()/1e6, name='Image Size (MP)'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# 3. Aspect Ratio\n",
    "if 'AspectRatio' in df_metadata.columns:\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=df_metadata['AspectRatio'].dropna(), name='Aspect Ratio', nbinsx=20),\n",
    "        row=1, col=3\n",
    "    )\n",
    "\n",
    "# 4. Temporal Distribution (if datetime available)\n",
    "# Placeholder for temporal analysis\n",
    "dates = pd.date_range(start='2023-01-01', periods=len(df_metadata), freq='H')\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=dates, y=np.random.randn(len(dates)).cumsum(), mode='lines', name='Temporal'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 5. Geospatial Coverage\n",
    "if 'Lat' in df_metadata.columns and 'Lon' in df_metadata.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_metadata['Lon'].dropna(),\n",
    "            y=df_metadata['Lat'].dropna(),\n",
    "            mode='markers',\n",
    "            marker=dict(size=8, color='blue'),\n",
    "            name='Coverage'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "# 6. Mode Distribution\n",
    "if 'ModeType' in df_metadata.columns:\n",
    "    mode_counts = df_metadata['ModeType'].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=mode_counts.index, y=mode_counts.values, name='Mode Count'),\n",
    "        row=2, col=3\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=800, showlegend=False, title_text=\" Dataset Statistical Overview\")\n",
    "fig.show()\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nðŸ“ˆ Key Statistics for ML:\")\n",
    "numeric_cols = df_metadata.select_dtypes(include=[np.number]).columns\n",
    "stats_summary = df_metadata[numeric_cols].describe()\n",
    "display(stats_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Specific Data Preparation Analysis\n",
    "\n",
    "### Key considerations for:\n",
    "1. **Input size standardization**\n",
    "2. **Dynamic range optimization**\n",
    "3. **Object size distribution**\n",
    "4. **Annotation quality metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTDETRPreprocessor:\n",
    "    \"\"\"Preprocessing pipeline optimized for on  SAR data\"\"\"\n",
    "    \n",
    "    def __init__(self, target_size: int = 640):\n",
    "        self.target_size = target_size\n",
    "        self.preprocessing_stats = {}\n",
    "    \n",
    "    def analyze_dynamic_range(self, image: np.ndarray) -> Dict:\n",
    "        \"\"\"Analyze dynamic range for optimal quantization\"\"\"\n",
    "        db_image = 20 * np.log10(np.abs(image) + 1e-10)\n",
    "        return {\n",
    "            'min_db': np.min(db_image),\n",
    "            'max_db': np.max(db_image),\n",
    "            'mean_db': np.mean(db_image),\n",
    "            'std_db': np.std(db_image),\n",
    "            'dynamic_range': np.max(db_image) - np.min(db_image),\n",
    "            'optimal_clip_range': (np.percentile(db_image, 1), np.percentile(db_image, 99))\n",
    "        }\n",
    "    \n",
    "    def normalize_sar_image(self, image: np.ndarray, method: str = 'minmax') -> np.ndarray:\n",
    "        \"\"\"Normalize SAR image for neural network input\"\"\"\n",
    "        # Convert to dB scale\n",
    "        db_image = 20 * np.log10(np.abs(image) + 1e-10)\n",
    "        \n",
    "        if method == 'minmax':\n",
    "            # Min-max normalization\n",
    "            vmin, vmax = np.percentile(db_image, [1, 99])\n",
    "            normalized = np.clip((db_image - vmin) / (vmax - vmin), 0, 1)\n",
    "        elif method == 'zscore':\n",
    "            # Z-score normalization\n",
    "            normalized = (db_image - np.mean(db_image)) / (np.std(db_image) + 1e-10)\n",
    "            normalized = (normalized + 3) / 6  # Map to ~[0, 1]\n",
    "        elif method == 'adaptive':\n",
    "            # Adaptive histogram equalization\n",
    "            from skimage import exposure\n",
    "            normalized = exposure.equalize_adapthist(db_image, clip_limit=0.03)\n",
    "        else:\n",
    "            normalized = db_image\n",
    "        \n",
    "        return np.clip(normalized, 0, 1)\n",
    "    \n",
    "    def resize_for_rtdetr(self, image: np.ndarray, maintain_aspect: bool = True) -> np.ndarray:\n",
    "        \"\"\"Resize image to input size\"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        if maintain_aspect:\n",
    "            # Maintain aspect ratio, pad if necessary\n",
    "            scale = self.target_size / max(h, w)\n",
    "            new_h, new_w = int(h * scale), int(w * scale)\n",
    "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            # Pad to square\n",
    "            pad_h = self.target_size - new_h\n",
    "            pad_w = self.target_size - new_w\n",
    "            padded = np.pad(resized, \n",
    "                          ((0, pad_h), (0, pad_w)) if len(resized.shape) == 2 \n",
    "                          else ((0, pad_h), (0, pad_w), (0, 0)),\n",
    "                          mode='constant')\n",
    "            return padded\n",
    "        else:\n",
    "            # Direct resize\n",
    "            return cv2.resize(image, (self.target_size, self.target_size), \n",
    "                            interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    def create_3channel_input(self, sar_image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Create 3-channel input from single-channel SAR data\"\"\"\n",
    "        # Channel 1: Original normalized image\n",
    "        ch1 = self.normalize_sar_image(sar_image, 'minmax')\n",
    "        \n",
    "        # Channel 2: Lee filtered (despeckled) version\n",
    "        from scipy.ndimage import uniform_filter\n",
    "        ch2 = uniform_filter(ch1, size=3)\n",
    "        \n",
    "        # Channel 3: Edge-enhanced version\n",
    "        ch3 = cv2.Laplacian(ch1, cv2.CV_64F)\n",
    "        ch3 = np.clip((ch3 - ch3.min()) / (ch3.max() - ch3.min()), 0, 1)\n",
    "        \n",
    "        return np.stack([ch1, ch2, ch3], axis=-1)\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = RTDETRPreprocessor(target_size=RTDETR_CONFIG['input_sizes'][0])\n",
    "\n",
    "print(\"ðŸ”§ Preprocessing Pipeline Initialized\")\n",
    "print(f\"Target input size: {preprocessor.target_size}x{preprocessor.target_size}\")\n",
    "print(\"Normalization methods available: minmax, zscore, adaptive\")\n",
    "print(\"3-channel strategy: [Original, Despeckled, Edge-enhanced]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Object Detection Annotation Analysis\n",
    "\n",
    "Analyzing annotation quality and distribution for object detection tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnotationAnalyzer:\n",
    "    \"\"\"Analyze object detection annotations for training\"\"\"\n",
    "    \n",
    "    def __init__(self, label_dir: Path):\n",
    "        self.label_dir = label_dir\n",
    "        self.annotations = []\n",
    "        self.stats = {}\n",
    "    \n",
    "    def load_annotations(self) -> None:\n",
    "        \"\"\"Load all annotation files\"\"\"\n",
    "        annotation_files = list(self.label_dir.glob('*.geojson')) + \\\n",
    "                          list(self.label_dir.glob('*.json'))\n",
    "        \n",
    "        for ann_file in tqdm(annotation_files, desc=\"Loading annotations\"):\n",
    "            try:\n",
    "                with open(ann_file) as f:\n",
    "                    data = json.load(f)\n",
    "                    self.annotations.append({\n",
    "                        'filename': ann_file.stem,\n",
    "                        'data': data\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to load {ann_file}: {e}\")\n",
    "    \n",
    "    def analyze_object_sizes(self) -> pd.DataFrame:\n",
    "        \"\"\"Analyze object size distribution\"\"\"\n",
    "        sizes = []\n",
    "        \n",
    "        for ann in self.annotations:\n",
    "            if 'features' in ann['data']:  # GeoJSON format\n",
    "                for feature in ann['data']['features']:\n",
    "                    geom = shape(feature['geometry'])\n",
    "                    sizes.append({\n",
    "                        'area': geom.area,\n",
    "                        'bounds': geom.bounds,\n",
    "                        'type': feature.get('properties', {}).get('class', 'unknown')\n",
    "                    })\n",
    "        \n",
    "        if sizes:\n",
    "            df_sizes = pd.DataFrame(sizes)\n",
    "            df_sizes['width'] = df_sizes['bounds'].apply(lambda x: x[2] - x[0] if x else 0)\n",
    "            df_sizes['height'] = df_sizes['bounds'].apply(lambda x: x[3] - x[1] if x else 0)\n",
    "            df_sizes['aspect_ratio'] = df_sizes['width'] / (df_sizes['height'] + 1e-6)\n",
    "            return df_sizes\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    def analyze_class_distribution(self) -> Dict:\n",
    "        \"\"\"Analyze class distribution and imbalance\"\"\"\n",
    "        class_counts = defaultdict(int)\n",
    "        \n",
    "        for ann in self.annotations:\n",
    "            if 'features' in ann['data']:\n",
    "                for feature in ann['data']['features']:\n",
    "                    class_name = feature.get('properties', {}).get('class', 'unknown')\n",
    "                    class_counts[class_name] += 1\n",
    "        \n",
    "        total = sum(class_counts.values())\n",
    "        class_dist = {k: v/total for k, v in class_counts.items()}\n",
    "        \n",
    "        # Calculate class imbalance ratio\n",
    "        if class_counts:\n",
    "            max_count = max(class_counts.values())\n",
    "            min_count = min(class_counts.values())\n",
    "            imbalance_ratio = max_count / (min_count + 1e-6)\n",
    "        else:\n",
    "            imbalance_ratio = 0\n",
    "        \n",
    "        return {\n",
    "            'class_counts': dict(class_counts),\n",
    "            'class_distribution': class_dist,\n",
    "            'imbalance_ratio': imbalance_ratio,\n",
    "            'total_objects': total\n",
    "        }\n",
    "    \n",
    "    def generate_annotation_report(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate comprehensive annotation quality report\"\"\"\n",
    "        self.load_annotations()\n",
    "        \n",
    "        class_stats = self.analyze_class_distribution()\n",
    "        size_df = self.analyze_object_sizes()\n",
    "        \n",
    "        report = {\n",
    "            'Metric': [\n",
    "                'Total Annotations',\n",
    "                'Total Objects',\n",
    "                'Unique Classes',\n",
    "                'Class Imbalance Ratio',\n",
    "                'Avg Objects per Image',\n",
    "                'Min Object Size (pixels)',\n",
    "                'Max Object Size (pixels)',\n",
    "                'Avg Object Size (pixels)'\n",
    "            ],\n",
    "            'Value': [\n",
    "                len(self.annotations),\n",
    "                class_stats['total_objects'],\n",
    "                len(class_stats['class_counts']),\n",
    "                f\"{class_stats['imbalance_ratio']:.2f}\",\n",
    "                f\"{class_stats['total_objects'] / max(len(self.annotations), 1):.1f}\",\n",
    "                f\"{size_df['area'].min():.0f}\" if not size_df.empty else 'N/A',\n",
    "                f\"{size_df['area'].max():.0f}\" if not size_df.empty else 'N/A',\n",
    "                f\"{size_df['area'].mean():.0f}\" if not size_df.empty else 'N/A'\n",
    "            ],\n",
    "            'ML Recommendation': [\n",
    "                'Augment if < 1000 images',\n",
    "                'Good if > 10000 objects',\n",
    "                'Consider merging if > 20 classes',\n",
    "                'Use weighted loss if > 3.0',\n",
    "                'Good density for detection',\n",
    "                'Filter if < 32 pixels',\n",
    "                'Split if > 512 pixels',\n",
    "                'Typical for SAR objects'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        return pd.DataFrame(report)\n",
    "\n",
    "# Run annotation analysis if label directory exists\n",
    "if label_dir.exists() and any(label_dir.iterdir()):\n",
    "    ann_analyzer = AnnotationAnalyzer(label_dir)\n",
    "    annotation_report = ann_analyzer.generate_annotation_report()\n",
    "    \n",
    "    print(\"\\nðŸ“‹ Annotation Quality Report:\")\n",
    "    display(annotation_report)\n",
    "else:\n",
    "    print(\"âš ï¸ No annotation directory found or empty. Skipping annotation analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Augmentation Strategies for SAR\n",
    "\n",
    "SAR-specific augmentation techniques that preserve physical properties while increasing dataset diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARDataAugmenter:\n",
    "    \"\"\"SAR-specific data augmentation for training\"\"\"\n",
    "    \n",
    "    def __init__(self, preserve_physics: bool = True):\n",
    "        self.preserve_physics = preserve_physics\n",
    "        self.augmentation_funcs = {\n",
    "            'speckle_noise': self.add_speckle_noise,\n",
    "            'rotation': self.rotate_sar,\n",
    "            'flip': self.flip_sar,\n",
    "            'intensity_shift': self.shift_intensity,\n",
    "            'elastic_deformation': self.elastic_transform,\n",
    "            'shadow_simulation': self.simulate_shadows,\n",
    "            'multi_look': self.simulate_multilook\n",
    "        }\n",
    "    \n",
    "    def add_speckle_noise(self, image: np.ndarray, var: float = 0.01) -> np.ndarray:\n",
    "        \"\"\"Add realistic speckle noise to SAR image\"\"\"\n",
    "        noise = np.random.gamma(1, var, image.shape)\n",
    "        return image * noise\n",
    "    \n",
    "    def rotate_sar(self, image: np.ndarray, angle: float = None) -> np.ndarray:\n",
    "        \"\"\"Rotate SAR image (physically valid for satellite viewing geometry changes)\"\"\"\n",
    "        if angle is None:\n",
    "            angle = np.random.uniform(-30, 30)  # Limited rotation range\n",
    "        \n",
    "        rows, cols = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "        return cv2.warpAffine(image, M, (cols, rows), borderMode=cv2.BORDER_REFLECT)\n",
    "    \n",
    "    def flip_sar(self, image: np.ndarray, direction: str = 'horizontal') -> np.ndarray:\n",
    "        \"\"\"Flip SAR image (valid for different orbit directions)\"\"\"\n",
    "        if direction == 'horizontal':\n",
    "            return cv2.flip(image, 1)\n",
    "        elif direction == 'vertical':\n",
    "            return cv2.flip(image, 0)\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def shift_intensity(self, image: np.ndarray, shift_range: float = 0.1) -> np.ndarray:\n",
    "        \"\"\"Simulate different calibration or atmospheric conditions\"\"\"\n",
    "        shift = np.random.uniform(-shift_range, shift_range)\n",
    "        return np.clip(image + shift, 0, 1)\n",
    "    \n",
    "    def elastic_transform(self, image: np.ndarray, alpha: float = 20, sigma: float = 3) -> np.ndarray:\n",
    "        \"\"\"Apply elastic deformation (simulates terrain variations)\"\"\"\n",
    "        random_state = np.random.RandomState(None)\n",
    "        shape = image.shape[:2]\n",
    "        \n",
    "        dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\") * alpha\n",
    "        dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\") * alpha\n",
    "        \n",
    "        x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
    "        indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "        \n",
    "        from scipy.ndimage import map_coordinates\n",
    "        return map_coordinates(image, indices, order=1).reshape(shape)\n",
    "    \n",
    "    def simulate_shadows(self, image: np.ndarray, num_shadows: int = 3) -> np.ndarray:\n",
    "        \"\"\"Simulate radar shadows from tall structures\"\"\"\n",
    "        img_copy = image.copy()\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        for _ in range(num_shadows):\n",
    "            # Random shadow parameters\n",
    "            x = np.random.randint(0, w)\n",
    "            y = np.random.randint(0, h)\n",
    "            shadow_width = np.random.randint(10, 50)\n",
    "            shadow_length = np.random.randint(20, 100)\n",
    "            angle = np.random.uniform(0, 360)\n",
    "            \n",
    "            # Create shadow mask\n",
    "            shadow = np.zeros((h, w))\n",
    "            cv2.ellipse(shadow, (x, y), (shadow_length, shadow_width), \n",
    "                       angle, 0, 360, 1, -1)\n",
    "            \n",
    "            # Apply shadow\n",
    "            img_copy = img_copy * (1 - shadow * 0.5)\n",
    "        \n",
    "        return img_copy\n",
    "    \n",
    "    def simulate_multilook(self, image: np.ndarray, num_looks: int = 4) -> np.ndarray:\n",
    "        \"\"\"Simulate different number of looks processing\"\"\"\n",
    "        # Add correlated speckle noise\n",
    "        noise_images = []\n",
    "        for _ in range(num_looks):\n",
    "            noise = np.random.gamma(1, 0.1/num_looks, image.shape)\n",
    "            noise_images.append(image * noise)\n",
    "        \n",
    "        # Average to reduce speckle\n",
    "        return np.mean(noise_images, axis=0)\n",
    "    \n",
    "    def augment_batch(self, images: List[np.ndarray], \n",
    "                     augmentations: List[str] = None) -> List[np.ndarray]:\n",
    "        \"\"\"Apply augmentations to a batch of images\"\"\"\n",
    "        if augmentations is None:\n",
    "            augmentations = list(self.augmentation_funcs.keys())\n",
    "        \n",
    "        augmented = []\n",
    "        for img in images:\n",
    "            aug_img = img.copy()\n",
    "            for aug_name in augmentations:\n",
    "                if np.random.random() > 0.5:  # 50% chance for each augmentation\n",
    "                    aug_func = self.augmentation_funcs[aug_name]\n",
    "                    aug_img = aug_func(aug_img)\n",
    "            augmented.append(aug_img)\n",
    "        \n",
    "        return augmented\n",
    "\n",
    "# Initialize augmenter\n",
    "augmenter = SARDataAugmenter(preserve_physics=True)\n",
    "\n",
    "# Demonstrate augmentation effects\n",
    "print(\"ðŸŽ¨ SAR Data Augmentation Pipeline\")\n",
    "print(f\"Available augmentations: {list(augmenter.augmentation_funcs.keys())}\")\n",
    "print(\"\\nAugmentation Strategy for:\")\n",
    "print(\"1. Speckle noise: Simulates different acquisition conditions\")\n",
    "print(\"2. Rotation: Accounts for different satellite passes\")\n",
    "print(\"3. Intensity shift: Simulates calibration variations\")\n",
    "print(\"4. Shadow simulation: Prepares model for urban environments\")\n",
    "print(\"5. Multi-look: Varies image quality characteristics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training/Validation/Test Split Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSplitter:\n",
    "    \"\"\"Intelligent dataset splitting for SAR imagery\"\"\"\n",
    "    \n",
    "    def __init__(self, metadata_df: pd.DataFrame):\n",
    "        self.df = metadata_df\n",
    "    \n",
    "    def stratified_split(self, stratify_by: List[str] = ['ModeType'], \n",
    "                        splits: List[float] = [0.7, 0.2, 0.1]) -> Dict:\n",
    "        \"\"\"Create stratified train/val/test split\"\"\"\n",
    "        # Ensure splits sum to 1.0\n",
    "        assert abs(sum(splits) - 1.0) < 1e-6, \"Splits must sum to 1.0\"\n",
    "        \n",
    "        # Create stratification key\n",
    "        strat_key = self.df[stratify_by].fillna('unknown').apply(lambda x: '_'.join(x.astype(str)), axis=1)\n",
    "        \n",
    "        # First split: train+val vs test\n",
    "        train_val_idx, test_idx = train_test_split(\n",
    "            self.df.index,\n",
    "            test_size=splits[2],\n",
    "            stratify=strat_key,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Second split: train vs val\n",
    "        val_size_adjusted = splits[1] / (splits[0] + splits[1])\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            train_val_idx,\n",
    "            test_size=val_size_adjusted,\n",
    "            stratify=strat_key[train_val_idx],\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'train': self.df.loc[train_idx],\n",
    "            'validation': self.df.loc[val_idx],\n",
    "            'test': self.df.loc[test_idx]\n",
    "        }\n",
    "    \n",
    "    def temporal_split(self, date_column: str = 'DateTime') -> Dict:\n",
    "        \"\"\"Split based on temporal ordering\"\"\"\n",
    "        if date_column not in self.df.columns:\n",
    "            print(f\"Warning: {date_column} not found. Using random split.\")\n",
    "            return self.stratified_split(stratify_by=[])\n",
    "        \n",
    "        sorted_df = self.df.sort_values(date_column)\n",
    "        n = len(sorted_df)\n",
    "        \n",
    "        train_end = int(n * 0.7)\n",
    "        val_end = int(n * 0.9)\n",
    "        \n",
    "        return {\n",
    "            'train': sorted_df.iloc[:train_end],\n",
    "            'validation': sorted_df.iloc[train_end:val_end],\n",
    "            'test': sorted_df.iloc[val_end:]\n",
    "        }\n",
    "    \n",
    "    def spatial_split(self, overlap_threshold: float = 0.1) -> Dict:\n",
    "        \"\"\"Split based on geographic location to avoid overlap\"\"\"\n",
    "        if 'Lat' not in self.df.columns or 'Lon' not in self.df.columns:\n",
    "            print(\"Warning: Geographic coordinates not found. Using random split.\")\n",
    "            return self.stratified_split(stratify_by=[])\n",
    "        \n",
    "        # Cluster locations\n",
    "        coords = self.df[['Lat', 'Lon']].dropna()\n",
    "        kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "        clusters = kmeans.fit_predict(coords)\n",
    "        \n",
    "        # Assign clusters to splits\n",
    "        unique_clusters = np.unique(clusters)\n",
    "        np.random.shuffle(unique_clusters)\n",
    "        \n",
    "        n_clusters = len(unique_clusters)\n",
    "        train_clusters = unique_clusters[:int(n_clusters * 0.7)]\n",
    "        val_clusters = unique_clusters[int(n_clusters * 0.7):int(n_clusters * 0.9)]\n",
    "        test_clusters = unique_clusters[int(n_clusters * 0.9):]\n",
    "        \n",
    "        return {\n",
    "            'train': self.df.iloc[np.isin(clusters, train_clusters)],\n",
    "            'validation': self.df.iloc[np.isin(clusters, val_clusters)],\n",
    "            'test': self.df.iloc[np.isin(clusters, test_clusters)]\n",
    "        }\n",
    "\n",
    "# Create splits\n",
    "splitter = DatasetSplitter(df_metadata)\n",
    "\n",
    "# Try stratified split\n",
    "if 'ModeType' in df_metadata.columns:\n",
    "    splits = splitter.stratified_split(stratify_by=['ModeType'])\n",
    "else:\n",
    "    splits = splitter.stratified_split(stratify_by=[])\n",
    "\n",
    "# Display split statistics\n",
    "split_stats = pd.DataFrame({\n",
    "    'Split': ['Train', 'Validation', 'Test'],\n",
    "    'Count': [len(splits['train']), len(splits['validation']), len(splits['test'])],\n",
    "    'Percentage': [\n",
    "        f\"{len(splits['train'])/len(df_metadata)*100:.1f}%\",\n",
    "        f\"{len(splits['validation'])/len(df_metadata)*100:.1f}%\",\n",
    "        f\"{len(splits['test'])/len(df_metadata)*100:.1f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nðŸ“Š Dataset Split Statistics:\")\n",
    "display(split_stats)\n",
    "\n",
    "# Verify stratification\n",
    "if 'ModeType' in df_metadata.columns:\n",
    "    print(\"\\nðŸ” Mode distribution across splits:\")\n",
    "    for split_name, split_df in splits.items():\n",
    "        mode_dist = split_df['ModeType'].value_counts(normalize=True)\n",
    "        print(f\"\\n{split_name.capitalize()}:\")\n",
    "        print(mode_dist.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Performance Benchmarking and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLRecommendationEngine:\n",
    "    \"\"\"Generate ML recommendations based on data analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, metadata_df: pd.DataFrame, quality_report: pd.DataFrame = None):\n",
    "        self.df = metadata_df\n",
    "        self.quality_report = quality_report\n",
    "        self.recommendations = []\n",
    "    \n",
    "    def analyze_dataset_size(self) -> None:\n",
    "        \"\"\"Recommendations based on dataset size\"\"\"\n",
    "        n_images = len(self.df)\n",
    "        \n",
    "        if n_images < 1000:\n",
    "            self.recommendations.append({\n",
    "                'category': 'Dataset Size',\n",
    "                'issue': f'Small dataset ({n_images} images)',\n",
    "                'recommendation': 'Apply aggressive augmentation (5-10x)',\n",
    "                'priority': 'High'\n",
    "            })\n",
    "        elif n_images < 5000:\n",
    "            self.recommendations.append({\n",
    "                'category': 'Dataset Size',\n",
    "                'issue': f'Medium dataset ({n_images} images)',\n",
    "                'recommendation': 'Apply moderate augmentation (3-5x)',\n",
    "                'priority': 'Medium'\n",
    "            })\n",
    "        else:\n",
    "            self.recommendations.append({\n",
    "                'category': 'Dataset Size',\n",
    "                'issue': f'Large dataset ({n_images} images)',\n",
    "                'recommendation': 'Focus on hard negative mining',\n",
    "                'priority': 'Low'\n",
    "            })\n",
    "    \n",
    "    def analyze_resolution_variance(self) -> None:\n",
    "        \"\"\"Recommendations based on resolution consistency\"\"\"\n",
    "        if 'NumRows' in self.df.columns and 'NumCols' in self.df.columns:\n",
    "            resolutions = self.df[['NumRows', 'NumCols']].dropna()\n",
    "            cv_rows = resolutions['NumRows'].std() / resolutions['NumRows'].mean()\n",
    "            cv_cols = resolutions['NumCols'].std() / resolutions['NumCols'].mean()\n",
    "            \n",
    "            if cv_rows > 0.2 or cv_cols > 0.2:\n",
    "                self.recommendations.append({\n",
    "                    'category': 'Image Resolution',\n",
    "                    'issue': 'High resolution variance',\n",
    "                    'recommendation': 'Use adaptive pooling in model architecture',\n",
    "                    'priority': 'High'\n",
    "                })\n",
    "    \n",
    "    def recommend_preprocessing(self) -> None:\n",
    "        \"\"\"Preprocessing recommendations for\"\"\"\n",
    "        self.recommendations.append({\n",
    "            'category': 'Preprocessing',\n",
    "            'issue': 'SAR speckle noise',\n",
    "            'recommendation': 'Apply Lee or Frost filter before training',\n",
    "            'priority': 'High'\n",
    "        })\n",
    "        \n",
    "        self.recommendations.append({\n",
    "            'category': 'Preprocessing',\n",
    "            'issue': 'Dynamic range',\n",
    "            'recommendation': 'Use log transformation and percentile clipping',\n",
    "            'priority': 'High'\n",
    "        })\n",
    "    \n",
    "    def recommend_model_config(self) -> None:\n",
    "        \"\"\"Model configuration recommendations\"\"\"\n",
    "        self.recommendations.append({\n",
    "            'category':  Config',\n",
    "            'issue': 'SAR grayscale input',\n",
    "            'recommendation': 'Use 3-channel strategy: [Original, Despeckled, Edge]',\n",
    "            'priority': 'Medium'\n",
    "        })\n",
    "        \n",
    "        self.recommendations.append({\n",
    "            'category':  Config',\n",
    "            'issue': 'Small object detection',\n",
    "            'recommendation': 'Add FPN layers and reduce stride',\n",
    "            'priority': 'High'\n",
    "        })\n",
    "    \n",
    "    def generate_recommendations(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate comprehensive recommendations\"\"\"\n",
    "        self.analyze_dataset_size()\n",
    "        self.analyze_resolution_variance()\n",
    "        self.recommend_preprocessing()\n",
    "        self.recommend_model_config()\n",
    "        \n",
    "        # Additional -specific recommendations\n",
    "        self.recommendations.append({\n",
    "            'category': '-Specific',\n",
    "            'issue': 'Orbit variations',\n",
    "            'recommendation': 'Include incidence angle as auxiliary input',\n",
    "            'priority': 'Medium'\n",
    "        })\n",
    "        \n",
    "        self.recommendations.append({\n",
    "            'category': 'Training Strategy',\n",
    "            'issue': 'Limited labeled data',\n",
    "            'recommendation': 'Use semi-supervised learning with pseudo-labels',\n",
    "            'priority': 'Medium'\n",
    "        })\n",
    "        \n",
    "        return pd.DataFrame(self.recommendations)\n",
    "\n",
    "# Generate recommendations\n",
    "recommender = MLRecommendationEngine(df_metadata)\n",
    "recommendations_df = recommender.generate_recommendations()\n",
    "\n",
    "print(\"\\nðŸŽ¯ ML Engineering Recommendations:\")\n",
    "display(recommendations_df.style.apply(\n",
    "    lambda x: ['background-color: #ffcccc' if v == 'High' else \n",
    "               'background-color: #ffffcc' if v == 'Medium' else \n",
    "               'background-color: #ccffcc' for v in x], \n",
    "    subset=['priority']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Pipeline Configuration\n",
    "\n",
    "Generate configuration files for the ML training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive pipeline configuration\n",
    "pipeline_config = {\n",
    "    'dataset': {\n",
    "        'name': '_SAR_Detection',\n",
    "        'total_images': len(df_metadata),\n",
    "        'image_format': 'SICD',\n",
    "        'annotation_format': 'GeoJSON',\n",
    "        'splits': {\n",
    "            'train': len(splits['train']),\n",
    "            'validation': len(splits['validation']),\n",
    "            'test': len(splits['test'])\n",
    "        }\n",
    "    },\n",
    "    'preprocessing': {\n",
    "        'normalization': 'minmax_percentile',\n",
    "        'input_size': RTDETR_CONFIG['input_sizes'][0],\n",
    "        'channels': 3,\n",
    "        'channel_strategy': ['original', 'despeckled', 'edge_enhanced'],\n",
    "        'filters': ['lee', 'frost'],\n",
    "        'dynamic_range_clip': [1, 99]  # percentiles\n",
    "    },\n",
    "    'augmentation': {\n",
    "        'enabled': True,\n",
    "        'factor': ML_CONFIG['augmentation_factor'],\n",
    "        'techniques': [\n",
    "            'speckle_noise',\n",
    "            'rotation',\n",
    "            'flip',\n",
    "            'intensity_shift',\n",
    "            'shadow_simulation'\n",
    "        ],\n",
    "        'probabilities': [0.5, 0.3, 0.5, 0.3, 0.2]\n",
    "    },\n",
    "    'model': {\n",
    "        'architecture': ',\n",
    "        'backbone': RTDETR_CONFIG['backbone'],\n",
    "        'input_size': RTDETR_CONFIG['input_sizes'],\n",
    "        'num_classes': len(ann_analyzer.analyze_class_distribution()['class_counts']) if 'ann_analyzer' in locals() else 10,\n",
    "        'anchor_sizes': RTDETR_CONFIG['anchor_sizes'],\n",
    "        'confidence_threshold': RTDETR_CONFIG['confidence_threshold'],\n",
    "        'nms_threshold': RTDETR_CONFIG['nms_threshold']\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': ML_CONFIG['batch_size'],\n",
    "        'learning_rate': ML_CONFIG['learning_rate'],\n",
    "        'epochs': ML_CONFIG['epochs'],\n",
    "        'optimizer': 'AdamW',\n",
    "        'scheduler': 'CosineAnnealingLR',\n",
    "        'early_stopping': ML_CONFIG['early_stopping_patience'],\n",
    "        'mixed_precision': True,\n",
    "        'gradient_clipping': 1.0\n",
    "    },\n",
    "    'evaluation': {\n",
    "        'metrics': ['mAP', 'mAP50', 'mAP75', 'precision', 'recall', 'f1'],\n",
    "        'iou_thresholds': [0.5, 0.75, 0.9],\n",
    "        'save_predictions': True,\n",
    "        'visualization_samples': 50\n",
    "    },\n",
    "    'hardware': {\n",
    "        'gpu': 'recommended',\n",
    "        'min_gpu_memory': '8GB',\n",
    "        'recommended_gpu': 'NVIDIA A100 or RTX 4090',\n",
    "        'num_workers': 4\n",
    "    },\n",
    "    'output': {\n",
    "        'checkpoint_dir': './checkpoints',\n",
    "        'log_dir': './logs',\n",
    "        'tensorboard': True,\n",
    "        'save_best_only': True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save configuration\n",
    "config_path = Path('_rtdetr_config.yaml')\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(pipeline_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Pipeline configuration saved to {config_path}\")\n",
    "print(\"\\nðŸ“‹ Configuration Summary:\")\n",
    "print(yaml.dump(pipeline_config, default_flow_style=False)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Next Steps\n",
    "\n",
    "### ðŸ“Š Analysis Complete!\n",
    "\n",
    "This notebook has provided comprehensive insights for developing models with  SAR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary report\n",
    "print(\"=\"*60)\n",
    "print(\"     SAR ML PIPELINE SUMMARY REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Dataset Overview:\")\n",
    "print(f\"  â€¢ Total Images: {len(df_metadata)}\")\n",
    "print(f\"  â€¢ Date Range: {df_metadata.index.min()} to {df_metadata.index.max()}\")\n",
    "if 'ModeType' in df_metadata.columns:\n",
    "    print(f\"  â€¢ Imaging Modes: {df_metadata['ModeType'].nunique()}\")\n",
    "if 'IncidenceAng' in df_metadata.columns:\n",
    "    print(f\"  â€¢ Incidence Angle Range: {df_metadata['IncidenceAng'].min():.1f}Â° - {df_metadata['IncidenceAng'].max():.1f}Â°\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Key Recommendations:\")\n",
    "high_priority = recommendations_df[recommendations_df['priority'] == 'High']\n",
    "for _, rec in high_priority.iterrows():\n",
    "    print(f\"  â€¢ {rec['recommendation']}\")\n",
    "\n",
    "print(\"\\nâš¡ Estimated Training Metrics:\")\n",
    "print(f\"  â€¢ Training samples: {len(splits['train'])}\")\n",
    "print(f\"  â€¢ After augmentation: ~{len(splits['train']) * ML_CONFIG['augmentation_factor']}\")\n",
    "print(f\"  â€¢ Estimated training time: ~{len(splits['train']) * ML_CONFIG['epochs'] / 1000:.1f} hours (on A100)\")\n",
    "print(f\"  â€¢ Expected mAP range: 0.65-0.85 (depending on object complexity)\")\n",
    "\n",
    "print(\"\\nðŸš€ Next Steps:\")\n",
    "print(\"  1. Review and adjust the generated configuration file\")\n",
    "print(\"  2. Set up the preprocessing pipeline with recommended filters\")\n",
    "print(\"  3. Implement the 3-channel input strategy\")\n",
    "print(\"  4. Configure with SAR-specific modifications\")\n",
    "print(\"  5. Begin training with careful monitoring of convergence\")\n",
    "print(\"  6. Implement active learning for continuous improvement\")\n",
    "\n",
    "print(\"\\nðŸ“ Generated Files:\")\n",
    "print(f\"  â€¢ Configuration: {config_path}\")\n",
    "print(f\"  â€¢ Metadata CSV: exported_metadata.csv\")\n",
    "print(f\"  â€¢ This notebook: _sar_ml_analysis.ipynb\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  Analysis complete! Ready for training.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}