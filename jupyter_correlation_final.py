# ===============================================================================
# JUPYTER NOTEBOOK: CEI/BEI Correlation Analysis (With Program Name Mapping)
# ===============================================================================

# ==============================================================================
# CELL 1: Setup and Imports
# ==============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Set plotting style
sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 100

# Import modules
from correlation_analysis_csv_final import (
    load_separate_csvs,
    add_derived_metrics_csv,
    create_mapping_template,
    load_program_mapping
)

from correlation_analysis import (
    calculate_correlations,
    plot_correlation_matrix,
    plot_scatterplot_matrix,
    print_summary_statistics
)

print("‚úÖ All imports successful!")
print("\n" + "="*80)
print("CEI/BEI CORRELATION ANALYSIS")
print("With Program Name Mapping Support")
print("="*80)

# ==============================================================================
# CELL 2: Create Program Name Mapping (Run Once)
# ==============================================================================

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# OPTION 1: Create a template to fill in
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Uncomment to create template:
# create_mapping_template("program_name_mapping.csv")
# print("‚úÖ Template created! Fill in your actual program names.")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# OPTION 2: Check what program names you have in each dataset
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Uncomment to check programs:
# cei_bei = pd.read_csv("cei_bei_data.csv")
# ontime = pd.read_csv("ontime_forecast.csv")
# 
# print("CEI/BEI Programs:")
# for prog in sorted(cei_bei['Program Name'].unique()):
#     print(f"  - {prog}")
# 
# print("\nMetrics Programs:")
# for prog in sorted(ontime['PRGRM_NAME'].unique()):
#     print(f"  - {prog}")

print("üí° Uncomment the code above to:")
print("   - Create a mapping template")
print("   - Check program names in your data")

# ==============================================================================
# CELL 3: Load Data with Program Name Mapping
# ==============================================================================

print("="*80)
print("LOADING DATA")
print("="*80)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# STEP 1: Define your program name mapping
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# METHOD A: Use a CSV file (Recommended)
program_mapping = "program_name_mapping.csv"

# METHOD B: Use a Python dictionary
# program_mapping = {
#     "Program Alpha": "ALPHA_PROGRAM",
#     "Program Beta": "BETA_PROGRAM",
#     "Program Gamma": "GAMMA_PROGRAM",
#     # Add all your programs here
# }

# METHOD C: No mapping needed (if names already match)
# program_mapping = None

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# STEP 2: Load all CSV files
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

complete_data = load_separate_csvs(
    cei_bei_csv="cei_bei_data.csv",              # ‚Üê UPDATE THIS PATH
    ontime_csv="ontime_forecast.csv",            # ‚Üê UPDATE THIS PATH
    preventable_csv="preventable_revisions.csv", # ‚Üê UPDATE THIS PATH
    design_error_csv="design_error_count.csv",   # ‚Üê UPDATE THIS PATH
    planned_ct_csv="planned_ct_releases.csv",    # ‚Üê UPDATE THIS PATH
    ct_releases_csv="ct_releases.csv",           # ‚Üê UPDATE THIS PATH
    program_mapping=program_mapping,             # ‚Üê Your mapping!
    verbose=True
)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# STEP 3: Add derived metrics
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

complete_data = add_derived_metrics_csv(complete_data, verbose=True)

print("\n‚úÖ Data loaded successfully!")
print(f"   Total records: {len(complete_data)}")
print(f"   Programs: {complete_data['PRGRM_NAME'].nunique()}")
print(f"   Date range: {complete_data['FM_REPORTING_MONTH'].min()} to {complete_data['FM_REPORTING_MONTH'].max()}")

display(complete_data.head(10))

# Save for backup
complete_data.to_csv('complete_metrics_cei_bei.csv', index=False)
print("\nüíæ Saved to: complete_metrics_cei_bei.csv")

# ==============================================================================
# CELL 4: Data Quality Check
# ==============================================================================

print("="*80)
print("DATA QUALITY CHECK")
print("="*80)

# Check for required columns
required_metrics = [
    'CEI', 'BEI',
    '% On-Time to Forecast',
    '% Preventable Revisions',
    'design_error_count',
    'planned_ct_releases',
    'ct_releases',
    'pct_planned',
    'design_error_rate'
]

# Add CEI/BEI components if available
if 'cei_hit' in complete_data.columns:
    required_metrics.extend(['cei_hit', 'cei_miss', 'cei_total', 'cei_success_rate'])
if 'bei_numerator' in complete_data.columns:
    required_metrics.extend(['bei_numerator', 'bei_denominator'])

print(f"\n‚úÖ Data loaded: {len(complete_data)} records")
print(f"   Programs: {complete_data['PRGRM_NAME'].nunique()}")

print("\nüìä Data Completeness:")
for metric in required_metrics:
    if metric in complete_data.columns:
        non_null = complete_data[metric].notna().sum()
        pct = (non_null / len(complete_data)) * 100
        status = "‚úÖ" if pct > 80 else "‚ö†Ô∏è" if pct > 50 else "‚ùå"
        print(f"   {status} {metric}: {non_null}/{len(complete_data)} ({pct:.1f}%)")

# Preview data
print("\nüìã Data Preview:")
display_cols = ['PRGRM_NAME', 'FM_REPORTING_MONTH', 'CEI', 'BEI', 
                '% On-Time to Forecast', 'design_error_count', 'ct_releases']
display(complete_data[display_cols].head(10))

# ==============================================================================
# CELL 5: Calculate Correlations
# ==============================================================================

print("="*80)
print("CALCULATING CORRELATIONS")
print("="*80)

corr_matrix, p_values = calculate_correlations(
    df=complete_data,
    method='pearson',
    min_observations=10,
    verbose=True
)

# Save correlation results
corr_matrix.to_csv('correlation_matrix_cei_bei.csv')
p_values.to_csv('p_values_matrix_cei_bei.csv')
print("\nüíæ Saved:")
print("   - correlation_matrix_cei_bei.csv")
print("   - p_values_matrix_cei_bei.csv")

# ==============================================================================
# CELL 6: Visualize Correlation Matrix
# ==============================================================================

print("="*80)
print("CREATING CORRELATION MATRIX VISUALIZATION")
print("="*80)

fig_corr = plot_correlation_matrix(
    corr_matrix=corr_matrix,
    p_values=p_values,
    figsize=(14, 12),
    save_path='correlation_matrix_cei_bei.png'
)

print("\nüìä Interpretation Guide:")
print("   - Blue = Positive correlation (move together)")
print("   - Red = Negative correlation (move opposite)")
print("   - Stars = Significance (* p<0.05, ** p<0.01, *** p<0.001)")

# ==============================================================================
# CELL 7: CEI & BEI Focus Analysis
# ==============================================================================

print("="*80)
print("ANALYZING: CEI & BEI vs Engineering Metrics")
print("="*80)

existing_metrics = ['CEI', 'BEI']
new_metrics = [
    '% On-Time to Forecast',
    '% Preventable Revisions',
    'design_error_rate',
    'pct_planned'
]

# Add component metrics if available
if 'cei_success_rate' in complete_data.columns:
    existing_metrics.append('cei_success_rate')

print("\nüìä Correlation Summary:")
print("="*80)

for existing in existing_metrics:
    if existing not in corr_matrix.index:
        continue
        
    print(f"\nüéØ {existing} correlations:")
    print("-"*80)
    
    correlations = []
    for new in new_metrics:
        if new in corr_matrix.columns:
            r = corr_matrix.loc[existing, new]
            p = p_values.loc[existing, new]
            sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'
            
            if abs(r) > 0.7:
                strength = "Very Strong"
            elif abs(r) > 0.5:
                strength = "Strong"
            elif abs(r) > 0.3:
                strength = "Moderate"
            else:
                strength = "Weak"
            
            direction = "positive" if r > 0 else "negative"
            
            correlations.append({
                'Engineering Metric': new,
                'r': f"{r:.3f}",
                'Sig': sig,
                'Interpretation': f"{strength} {direction}"
            })
    
    if correlations:
        corr_df = pd.DataFrame(correlations)
        display(corr_df)

# ==============================================================================
# CELL 8: CEI vs BEI Relationship
# ==============================================================================

print("="*80)
print("CEI vs BEI RELATIONSHIP")
print("="*80)

plot_data = complete_data[['CEI', 'BEI']].dropna()

if len(plot_data) > 0:
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Scatter with regression
    axes[0].scatter(plot_data['CEI'], plot_data['BEI'], alpha=0.5, s=50, color='steelblue')
    z = np.polyfit(plot_data['CEI'], plot_data['BEI'], 1)
    p = np.poly1d(z)
    x_line = np.linspace(plot_data['CEI'].min(), plot_data['CEI'].max(), 100)
    axes[0].plot(x_line, p(x_line), "r-", linewidth=2, label='Regression')
    
    r = plot_data.corr().iloc[0, 1]
    axes[0].text(0.05, 0.95, f'r = {r:.3f}\nn = {len(plot_data)}',
                transform=axes[0].transAxes, fontsize=12,
                verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    axes[0].set_xlabel('CEI', fontsize=12)
    axes[0].set_ylabel('BEI', fontsize=12)
    axes[0].set_title('Relationship: CEI vs BEI', fontsize=14, fontweight='bold')
    axes[0].grid(True, alpha=0.3)
    axes[0].legend()
    
    # Density plot
    axes[1].hexbin(plot_data['CEI'], plot_data['BEI'], gridsize=20, cmap='Blues', alpha=0.8)
    axes[1].set_xlabel('CEI', fontsize=12)
    axes[1].set_ylabel('BEI', fontsize=12)
    axes[1].set_title('Density Plot', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('cei_vs_bei.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"\nüìä Correlation between CEI and BEI: {r:.3f}")
    print(f"   Sample size: {len(plot_data)}")
    
    if abs(r) > 0.7:
        print(f"\n‚úÖ STRONG RELATIONSHIP!")
        if r > 0:
            print("   ‚Üí Higher CEI ‚Üí Higher BEI")
        else:
            print("   ‚Üí Higher CEI ‚Üí Lower BEI")
    elif abs(r) > 0.5:
        print(f"\n‚ö†Ô∏è  MODERATE RELATIONSHIP")
    else:
        print(f"\n‚ùå WEAK RELATIONSHIP")
        print("   ‚Üí CEI and BEI are mostly independent")

# ==============================================================================
# CELL 9: Key Findings Summary
# ==============================================================================

print("="*80)
print("KEY FINDINGS")
print("="*80)

# Find top 10 correlations
top_corr = []
for i in range(len(corr_matrix)):
    for j in range(i+1, len(corr_matrix)):
        col1 = corr_matrix.columns[i]
        col2 = corr_matrix.columns[j]
        r = corr_matrix.iloc[i, j]
        p = p_values.iloc[i, j]
        if not np.isnan(r):
            top_corr.append((col1, col2, r, p))

top_corr.sort(key=lambda x: abs(x[2]), reverse=True)

print("\nüìä Top 10 Strongest Correlations:")
print("="*80)
for i, (col1, col2, r, p) in enumerate(top_corr[:10], 1):
    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else ''
    print(f"\n{i}. {col1} ‚Üî {col2}")
    print(f"   r = {r:.3f} {sig} (p = {p:.4f})")

# ==============================================================================
# CELL 10: Export Results
# ==============================================================================

print("\n" + "="*80)
print("EXPORTING RESULTS")
print("="*80)

# Save summary
with open('analysis_summary_cei_bei.txt', 'w') as f:
    f.write("="*80 + "\n")
    f.write("CEI/BEI CORRELATION ANALYSIS - SUMMARY\n")
    f.write("="*80 + "\n\n")
    f.write(f"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write(f"Records: {len(complete_data)}\n")
    f.write(f"Programs: {complete_data['PRGRM_NAME'].nunique()}\n")
    f.write(f"Date Range: {complete_data['FM_REPORTING_MONTH'].min()} to {complete_data['FM_REPORTING_MONTH'].max()}\n")
    
    f.write("\n" + "="*80 + "\n")
    f.write("TOP CORRELATIONS\n")
    f.write("="*80 + "\n\n")
    
    for i, (col1, col2, r, p) in enumerate(top_corr[:10], 1):
        sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else ''
        f.write(f"{i}. {col1} ‚Üî {col2}\n")
        f.write(f"   r = {r:.3f} {sig} (p = {p:.4f})\n\n")

print("‚úÖ Results exported!")
print("\nüìÅ Generated files:")
print("   ‚Ä¢ complete_metrics_cei_bei.csv")
print("   ‚Ä¢ correlation_matrix_cei_bei.csv")
print("   ‚Ä¢ p_values_matrix_cei_bei.csv")
print("   ‚Ä¢ correlation_matrix_cei_bei.png")
print("   ‚Ä¢ cei_vs_bei.png")
print("   ‚Ä¢ analysis_summary_cei_bei.txt")

print("\nüéâ Analysis complete!")

# ==============================================================================
# CELL 11: Recommendations
# ==============================================================================

print("="*80)
print("ACTIONABLE RECOMMENDATIONS")
print("="*80)

print("""
Based on your correlation analysis:

1Ô∏è‚É£  FOCUS ON HIGH-IMPACT METRICS
   ‚Üí Look for strong negative correlations with CEI/BEI
   ‚Üí Example: If design_error_rate ‚Üî CEI = -0.75, reducing errors will improve CEI
   ‚Üí Prioritize improvements that affect both CEI and BEI

2Ô∏è‚É£  UNDERSTAND CEI vs BEI RELATIONSHIP
   ‚Üí If highly correlated (r > 0.7): They measure similar aspects
   ‚Üí If weakly correlated (r < 0.3): They capture different dimensions
   ‚Üí Use this to understand what each metric really measures

3Ô∏è‚É£  IDENTIFY LEADING INDICATORS
   ‚Üí Which engineering metrics predict future CEI/BEI?
   ‚Üí Strong correlations suggest predictive relationships
   ‚Üí Use these for early warning systems

4Ô∏è‚É£  QUALITY vs PLANNING vs TIMELINESS
   ‚Üí Compare correlations of:
     ‚Ä¢ Quality metrics (% Preventable, Design Errors) with CEI/BEI
     ‚Ä¢ Planning metrics (% Planned) with CEI/BEI
     ‚Ä¢ Timeliness metrics (% On-Time) with CEI/BEI
   ‚Üí Focus on the dimension with strongest impact

5Ô∏è‚É£  PROGRAM-LEVEL ANALYSIS
   ‚Üí Re-run analysis for individual programs
   ‚Üí Some programs may have different patterns
   ‚Üí Tailor interventions to specific programs

6Ô∏è‚É£  MONITOR OVER TIME
   ‚Üí Re-run this analysis monthly/quarterly
   ‚Üí Track how correlations change
   ‚Üí Alert if relationships break down

üìä Use the visualizations to communicate findings to stakeholders!
""")

print("="*80)
