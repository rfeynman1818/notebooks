{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ba0b48",
   "metadata": {},
   "source": [
    "# DriftLens + FireRisk + Vision Transformer\n",
    "\n",
    "This notebook reproduces the DriftLens image experiments originally done on STL-10,\n",
    "but using the FireRisk dataset and Vision Transformers (ViT):\n",
    "\n",
    "1. Setup and data loading for FireRisk  \n",
    "2. Train a ViT on FireRisk  \n",
    "3. Extract embeddings and set up DriftLens baseline/thresholds  \n",
    "4. Experiment A: \"New class\" drift (analogous to use case 7.1)  \n",
    "5. Experiment B: Gaussian blur drift (analogous to use case 8)\n",
    "\n",
    "You must:\n",
    "- Download and extract FireRisk under `data/FireRisk/images`\n",
    "- Have a GPU if you want ViT training to be practical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf8b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q driftlens timm torch torchvision matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6783248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, math, random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from driftlens.driftlens import DriftLens\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "DATA_ROOT = \"data/FireRisk\"   # change if needed\n",
    "IMG_DIR = os.path.join(DATA_ROOT, \"images\")\n",
    "assert os.path.isdir(IMG_DIR), f\"Expected images under {IMG_DIR}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireRiskDataset(Dataset):\n",
    "    def __init__(self, root, split=\"train\", transform=None, classes_subset=None, seed=42, split_ratios=(0.7, 0.15, 0.15)):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        pattern = os.path.join(root, \"images\", \"*.png\")\n",
    "        all_paths = sorted(glob.glob(pattern))\n",
    "        assert all_paths, f\"No PNGs found under {pattern}\"\n",
    "\n",
    "        paths, labels = [], []\n",
    "        for p in all_paths:\n",
    "            fname = os.path.basename(p)\n",
    "            parts = fname.split(\"_\")\n",
    "            grid_code = int(parts[1])\n",
    "            if classes_subset is not None and grid_code not in classes_subset:\n",
    "                continue\n",
    "            paths.append(p)\n",
    "            labels.append(grid_code - 1)\n",
    "\n",
    "        n = len(paths)\n",
    "        idx = np.arange(n)\n",
    "        y = np.array(labels)\n",
    "        train_ratio, val_ratio, test_ratio = split_ratios\n",
    "        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6\n",
    "\n",
    "        train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
    "            idx, y, test_size=(1 - train_ratio), stratify=y, random_state=seed\n",
    "        )\n",
    "        rel_val_ratio = val_ratio / (val_ratio + test_ratio)\n",
    "        val_idx, test_idx, y_val, y_test = train_test_split(\n",
    "            temp_idx, y_temp, test_size=(1 - rel_val_ratio), stratify=y_temp, random_state=seed\n",
    "        )\n",
    "\n",
    "        if split == \"train\":\n",
    "            use_idx = train_idx\n",
    "        elif split == \"val\":\n",
    "            use_idx = val_idx\n",
    "        elif split == \"test\":\n",
    "            use_idx = test_idx\n",
    "        else:\n",
    "            raise ValueError(split)\n",
    "\n",
    "        self.paths = [paths[i] for i in use_idx]\n",
    "        self.labels = [labels[i] for i in use_idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.paths[i]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.labels[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "train_ds_full = FireRiskDataset(DATA_ROOT, split=\"train\", transform=img_transform, classes_subset=None)\n",
    "val_ds_full   = FireRiskDataset(DATA_ROOT, split=\"val\",   transform=img_transform, classes_subset=None)\n",
    "test_ds_full  = FireRiskDataset(DATA_ROOT, split=\"test\",  transform=img_transform, classes_subset=None)\n",
    "\n",
    "train_loader_full = DataLoader(train_ds_full, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
    "val_loader_full   = DataLoader(val_ds_full,   batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader_full  = DataLoader(test_ds_full,  batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "len(train_ds_full), len(val_ds_full), len(test_ds_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit(num_classes):\n",
    "    model = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "    if hasattr(model, \"head\"):\n",
    "        in_features = model.head.in_features\n",
    "        model.head = nn.Linear(in_features, num_classes)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unexpected ViT model structure.\")\n",
    "    model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3bd7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loader, optimizer=None, criterion=None):\n",
    "    train = optimizer is not None\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "            feats = model.forward_features(x)\n",
    "            logits = model.head(feats)\n",
    "            loss = criterion(logits, y) if criterion is not None else None\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if loss is not None:\n",
    "                total_loss += float(loss.item()) * x.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total if total > 0 else 0.0\n",
    "    acc = total_correct / total if total > 0 else 0.0\n",
    "    return avg_loss, acc\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=10, lr=3e-4, wd=0.05):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc = run_epoch(model, val_loader)\n",
    "        history.append((epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "        print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} acc={train_acc:.4f} | val_loss={val_loss:.4f} acc={val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d954ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_embeddings_and_preds(model, loader):\n",
    "    model.eval()\n",
    "    all_E, all_Y_hat, all_Y_true = [], [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        feats = model.forward_features(x)\n",
    "        logits = model.head(feats)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_E.append(feats.cpu())\n",
    "        all_Y_hat.append(preds.cpu())\n",
    "        all_Y_true.append(y)\n",
    "    E = torch.cat(all_E, dim=0).numpy()\n",
    "    Y_hat = torch.cat(all_Y_hat, dim=0).numpy()\n",
    "    Y_true = torch.cat(all_Y_true, dim=0).numpy()\n",
    "    return E, Y_hat, Y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf379ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_driftlens_baseline(E_train, Y_pred_train, E_thr, Y_pred_thr,\n",
    "                           batch_n_pc=150, per_label_n_pc=75,\n",
    "                           window_size=1000, n_samples=10000):\n",
    "    label_list = sorted(np.unique(Y_pred_train))\n",
    "    dl = DriftLens()\n",
    "    baseline = dl.estimate_baseline(\n",
    "        E=E_train,\n",
    "        Y=Y_pred_train,\n",
    "        label_list=label_list,\n",
    "        batch_n_pc=batch_n_pc,\n",
    "        per_label_n_pc=per_label_n_pc,\n",
    "    )\n",
    "    per_batch_sorted, per_label_sorted = dl.random_sampling_threshold_estimation(\n",
    "        label_list=label_list,\n",
    "        E=E_thr,\n",
    "        Y=Y_pred_thr,\n",
    "        batch_n_pc=batch_n_pc,\n",
    "        per_label_n_pc=per_label_n_pc,\n",
    "        window_size=window_size,\n",
    "        n_samples=n_samples,\n",
    "        flag_shuffle=True,\n",
    "        flag_replacement=True,\n",
    "    )\n",
    "    return dl, baseline, per_batch_sorted, per_label_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_window_distances(dl, E_stream, Yp_stream, window_size):\n",
    "    n = E_stream.shape[0]\n",
    "    n_windows = n // window_size\n",
    "    distances = []\n",
    "    for w in range(n_windows):\n",
    "        s = w * window_size\n",
    "        e = s + window_size\n",
    "        Ew = E_stream[s:e]\n",
    "        Ypw = Yp_stream[s:e]\n",
    "        dist = dl.compute_window_distribution_distances(Ew, Ypw)\n",
    "        distances.append(dist)\n",
    "    return np.array(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_train_nc = {1, 2, 3, 4, 5, 6}\n",
    "classes_new_nc = {7}\n",
    "\n",
    "train_ds_nc = FireRiskDataset(DATA_ROOT, split=\"train\", transform=img_transform, classes_subset=classes_train_nc)\n",
    "val_ds_nc   = FireRiskDataset(DATA_ROOT, split=\"val\",   transform=img_transform, classes_subset=classes_train_nc)\n",
    "test_ds_nc  = FireRiskDataset(DATA_ROOT, split=\"test\",  transform=img_transform, classes_subset=classes_train_nc)\n",
    "\n",
    "train_loader_nc = DataLoader(train_ds_nc, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
    "val_loader_nc   = DataLoader(val_ds_nc,   batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader_nc  = DataLoader(test_ds_nc,  batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "len(train_ds_nc), len(val_ds_nc), len(test_ds_nc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_nc = len(classes_train_nc)\n",
    "model_nc = create_vit(num_classes=num_classes_nc)\n",
    "history_nc = train_model(model_nc, train_loader_nc, val_loader_nc, epochs=10, lr=3e-4, wd=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c9afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_train_nc, Yp_train_nc, _ = get_embeddings_and_preds(model_nc, train_loader_nc)\n",
    "E_thr_nc,   Yp_thr_nc,   _ = get_embeddings_and_preds(model_nc, test_loader_nc)\n",
    "\n",
    "dl_nc, baseline_nc, per_batch_sorted_nc, per_label_sorted_nc = fit_driftlens_baseline(\n",
    "    E_train_nc, Yp_train_nc, E_thr_nc, Yp_thr_nc,\n",
    "    batch_n_pc=150, per_label_n_pc=75,\n",
    "    window_size=1000, n_samples=10000,\n",
    ")\n",
    "\n",
    "sorted(np.unique(Yp_train_nc)), sorted(np.unique(Yp_thr_nc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_all = FireRiskDataset(DATA_ROOT, split=\"test\", transform=img_transform, classes_subset=None)\n",
    "labels_all = test_ds_all.labels\n",
    "\n",
    "indices_by_class = {}\n",
    "for idx, y in enumerate(labels_all):\n",
    "    c = y + 1\n",
    "    indices_by_class.setdefault(c, []).append(idx)\n",
    "\n",
    "for c in indices_by_class:\n",
    "    random.shuffle(indices_by_class[c])\n",
    "\n",
    "pre_drift_len = 40000\n",
    "post_drift_len = 40000\n",
    "window_size_nc = 1000\n",
    "\n",
    "pre_indices = []\n",
    "while len(pre_indices) < pre_drift_len:\n",
    "    for c in classes_train_nc:\n",
    "        if indices_by_class[c]:\n",
    "            pre_indices.append(indices_by_class[c].pop())\n",
    "        if len(pre_indices) >= pre_drift_len:\n",
    "            break\n",
    "\n",
    "post_indices = []\n",
    "while len(post_indices) < post_drift_len:\n",
    "    for c in classes_train_nc | classes_new_nc:\n",
    "        if indices_by_class[c]:\n",
    "            post_indices.append(indices_by_class[c].pop())\n",
    "        if len(post_indices) >= post_drift_len:\n",
    "            break\n",
    "\n",
    "stream_indices_nc = pre_indices + post_indices\n",
    "stream_ds_nc = Subset(test_ds_all, stream_indices_nc)\n",
    "stream_loader_nc = DataLoader(stream_ds_nc, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "len(stream_ds_nc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_stream_nc, Yp_stream_nc, Ytrue_stream_nc = get_embeddings_and_preds(model_nc, stream_loader_nc)\n",
    "distances_nc = compute_window_distances(dl_nc, E_stream_nc, Yp_stream_nc, window_size=window_size_nc)\n",
    "len(distances_nc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a008b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(distances_nc, marker=\"o\")\n",
    "plt.axvline(x=(pre_drift_len // window_size_nc) - 0.5, linestyle=\"--\")\n",
    "plt.xlabel(\"Window index\")\n",
    "plt.ylabel(\"DriftLens distance\")\n",
    "plt.title(\"New-class drift (water) – FireRisk + ViT\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5921c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_full = len(set(train_ds_full.labels))\n",
    "model_full = create_vit(num_classes=num_classes_full)\n",
    "history_full = train_model(model_full, train_loader_full, val_loader_full, epochs=10, lr=3e-4, wd=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_train_full, Yp_train_full, _ = get_embeddings_and_preds(model_full, train_loader_full)\n",
    "E_thr_full,   Yp_thr_full,   _ = get_embeddings_and_preds(model_full, test_loader_full)\n",
    "\n",
    "dl_full, baseline_full, per_batch_sorted_full, per_label_sorted_full = fit_driftlens_baseline(\n",
    "    E_train_full, Yp_train_full, E_thr_full, Yp_thr_full,\n",
    "    batch_n_pc=150, per_label_n_pc=75,\n",
    "    window_size=1000, n_samples=10000,\n",
    ")\n",
    "\n",
    "sorted(np.unique(Yp_train_full)), sorted(np.unique(Yp_thr_full))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f93445",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.GaussianBlur(kernel_size=11, sigma=3.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "base_ds_clean = FireRiskDataset(DATA_ROOT, split=\"test\", transform=img_transform,    classes_subset=None)\n",
    "base_ds_blur  = FireRiskDataset(DATA_ROOT, split=\"test\", transform=blur_transform,  classes_subset=None)\n",
    "\n",
    "assert base_ds_clean.paths == base_ds_blur.paths\n",
    "assert base_ds_clean.labels == base_ds_blur.labels\n",
    "\n",
    "clean_loader = DataLoader(base_ds_clean, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "blur_loader  = DataLoader(base_ds_blur,  batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "len(base_ds_clean), len(base_ds_blur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_clean, Yp_clean, _ = get_embeddings_and_preds(model_full, clean_loader)\n",
    "E_blur,  Yp_blur,  _ = get_embeddings_and_preds(model_full, blur_loader)\n",
    "\n",
    "window_size_blur = 1000\n",
    "n_clean = 40000\n",
    "n_blur = 40000\n",
    "\n",
    "E_stream_blur = np.concatenate([E_clean[:n_clean], E_blur[:n_blur]], axis=0)\n",
    "Yp_stream_blur = np.concatenate([Yp_clean[:n_clean], Yp_blur[:n_blur]], axis=0)\n",
    "\n",
    "len(E_stream_blur), len(Yp_stream_blur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abcf908",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_blur = compute_window_distances(dl_full, E_stream_blur, Yp_stream_blur, window_size=window_size_blur)\n",
    "len(distances_blur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec44ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(distances_blur, marker=\"o\")\n",
    "plt.axvline(x=(n_clean // window_size_blur) - 0.5, linestyle=\"--\")\n",
    "plt.xlabel(\"Window index\")\n",
    "plt.ylabel(\"DriftLens distance\")\n",
    "plt.title(\"Gaussian blur drift – FireRisk + ViT\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
